In step 1, we parse the PDF file of the original paper to extract texts, tables, and figures. Since tables in the original paper may also serve as supplementary explanations in slides, we convert tables into image format for easy insertion during slide generation. Next, we perform Adaptive Cross-Modal Alignment, matching each Figure with all relevant sentences and paragraphs in the text, which is step 2.
In step 3, we conduct Narrative Construction to build a storytelling framework. To create a presentation that aligns with human understanding of research papers, we adopt a question-driven narrative structure. This approach is based on answering key questions, such as "What problem does it solve?" and "What are the unique and outstanding aspects of this paper compared to others?" By addressing these questions, we guide the audience to understand the paper in a logical and intuitive manner, rather than forcing them to follow the linear structure of the original document. This cross-sectional reorganization connects relevant concepts from different parts of the paper, creating thematic continuity. This narrative structure presents information in easily understandable conceptual units, rather than strict document order, thereby reducing cognitive load and providing a clear narrative arc. Finally in step 4, we use the retrieved content to rewrite and plan the slides using a large language model (LLM), generating the content plan and layout plan for the slides. The slides with voiceover narration are then generated by LLM agents.
This expanded explanation addresses the reviewers' request while maintaining our paper's focus on the alignment challenge. The complete system implementation will be detailed in subsequent publications.
